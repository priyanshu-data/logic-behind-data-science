ADA BOOST
By Aman :
           Example : 
                     Age              BMI                 Gender
                     25               24                    F
                     26               25                    F
                     41               31                    M
                     62               30                    M
                     
                     Let's try ada boost here :
                     how does this algorithm works ?
                     
                     step 1: First it will assign intial weights.(The weights should be like if we sum all the weights it should be 1.in above example it should be 1/4=.....
                     Ada boost is a sequential learning process.
                     
                     Now,the first or the weak learner or the base model will be fitted on above data.
                     Here weak learners are stumps(one root and two leaves).
                     
                     How to create this stump : with the help of gini index,entropy gain .
                     It will select a condition and stump will be created.
                     
                     After the stump is created the data will be tested for accuracy on this stump. Now there's a possibilty some of the records are missclassified.
                     
                     Now in the next iteration initial weights are changed ,now the weight of the misclassified record will go up and the weight of the others will come down to normalize properly.
                     So ,we can say in the next iteration more importance is given to the misclassified record.Here it will try to classify the record more accurately.
                     
                     And this process of weak learning continues 
                     
                     
                     THE NAME IS ADABOOST OR ADAPTIVE BOOST because it adapts to previous model.
                     Finally, last model will be the combination of these weak learners







By Krish :

HOW BOOSTING TECHNIQUE WORK-
CONSIDER A EXAMPLE OF RECORD FILE(7 FILES)
step 1 : create base model
       : This model can be any model.
     
NOW,this model fails to classify 2 files
ONLY THOSE FILES WILL BE SENT TO THE NEXT MODEL (WHICH IS A SEQUENTIAL MODEL) ALL THE DATAPOINTS WILL BE TRAINED BY THIS MODEL.

ALSO, if a record is further classified incorrectly,it will pass on to next model.

ADA BOOST:
Consider a file with 7 records
step 1: They will be assigned a sample weight
FORMULA is w=1/n  ,where n= no.of records
so here it will be 1/7=0.142

NOTE: summation of sample weight is always 1

step 2 : create a base stumps(stumps means one depth and any number of leaves)
for each and every feature a stump is created(suppose it has 3 features so 3 stumps will be created)

NOW,in this which one to select as a base model.
There are two criteria to select entropy and gini impurity,the low value will be selected.

AFTER this,
suppose it has done two classification incorrectly.
We will take total error value
         =sampling the total errors 
         =1/7 + 1/7 = 0.284

Performance of stump : 
              =1/2*log to the base e (1-TE/TE)
Some value will come.

why we need to do performance of stump : 
to update the value of sample weight we require performance of stump value.

How to update the new weight:
     =old weight*e raise to performance of stump value.

THIS WEIGHT IS FOR WRONG CLASSIFIED DATAPOINT

TO decrease the weight of the old datapoints
        =old weight*e raise to  minus performance stump value.
        
Here the updated values summation is not 1,to make summation as 1 , we take summation of the updated weights one will have a number(suppose it has 0.68),so next step is 
divide 0.68 to each and every updated weight column(so that one will have normalized value)


now for normalization
we take summation of updated weight and divide that number by each updated weight.
NOW THE SUMMATION WILL BE ONE.

NOW WE WILL FIT THE DATASET TO THIS NORMALIZED VALUE.

WITH THE HELP OF THIS NORMALIZED VALUE BUCKET WILL BE CREATED.
WHAT IS A BUCKET

  : suppose normalized weight has 0.06 ,0.52,0.06 and so on

bucket for 0.06 will be from 0 to 0.06
bucket for 0.52 will be 0.06 to 0.58(how 0.58 , simple add 0.06+0.52)
and so on

now the algorithm will run the iteration(the number for iteration provided by user) to select different records from these older dataset.

Suppose a random value is selected 0.44,now it will see 0.44 falls in which bucket,it will be populated to the new dataset and same for all other iteration.
and process continues until the number provided for the decision tree is done.
Now i have a new dataset and i will try new decision tree stump,again the process is continued.
WHEN WE WILL COMPARE AND WE WILL SEE THERE WILL BE LESS ERROR AT THE FINAL MODEL COMPARED TO THE NORMALIZED WEIGHT IN THE INITIAL.
NOW WE HAVE MANY DECISION TREES stumps.(many weak learners combine to make one strong learner)

After this,voting goes,
here also voting is done and weak learner becomes one big strong learner.



DISADVANTAGE OD ADABOOST : 
                           It is sensitive to noisy data or the outliers.
